% !TEX root = ../Thesis.tex
\begin{document}
\documentclass[Thesis.tex]{subfiles}
\chapter{Intelligent Search}
\label{ch:intelligent_search}

\section{Research Use Case}
With the set of methods used throughout this work, we can address a related, but distinct problem. Say for research purposes it is necessary to find as many documents of patients with a certain feature as possible. Traditionally this can be done with the help of string matching algorithms, that search the database. Even in easy scenarios, though, these algorithms might fail to retrieve all relevant documents. As mentioned earlier, diseases are spelled differently in different documents. Additionally, a string matching algorithm will return documents, in which a specific disease is mentioned in the family anamnesis, while one is only interested in patients having this disease themselves. In the specific use case we envision a researcher starts with the physician letter of one patient and is interested in retrieving similar patients from the database. The initial letter is given as input to our system and the most similar letter is retrieved from the database. The user has to decide whether this letter indeed has the demanded feature. The document is then either labeled as relevant or non-relevant. This procedure of retrieving one letter and deciding about its usefulness is repeated until the user has found sufficiently many letters with the required feature. We can address this use case with our embedding methods in the following way.

\section{Search System}
To obtain our goal of retrieving the letters with the required features, we make use of a hybrid approach of an exemplar classifier and logistic regression. In the beginning we use the exemplar classifier to retrieve more samples. The next document to be retrieved is the one with highest average cosine similarity to the thus far obtained true positive samples. Note that in the beginning this is equivalent to the standard recommending procedure, as the letter with highest cosine similarity to one reference letter is retrieved. The subject has then to label the retrieved letter as either relevant or non-relevant. Once enough letters have been labeled, the exemplar classifier is replaced by a logistic regression classifier (lrc). This lrc is trained with all thus far labeled documents. The next letter to be retrieved is the one that the lrc assigns highest probability. It is labeled by the subject and the lrc is retrained with the new set of labeled samples. Thereby one can retrieve as many relevant letters as desired. The important measure of performance for this research system is: How many irrelevant or false positive samples have to be looked through for every relevant or true positive sample obtained. This quantity can be calculated as $FP/TP$, i.e. the number of false positives divided by the number of true positives. We can measure it for different fractions of relevant letters retrieved. It is equivalent to measuring precision at different levels of recall, but easier interpretable for the usefulness of this particular system.

\section{System Performance}
To measure $FP/TP$ empirically we take a subset of 135 physician letters and label them manually for five prevalent diseases---``Chronic lymphocytic leukemia'' (cll), ``multiple myeloma'' (mm), ``breast cancer'' (bc), ``follicular lymphoma'' (fl) and ``diffuse large B-cell lymphoma'' (dlbcl). In the subset of 135 letters these diseases appear between 9 and 14 times. We start out with one letter from one of the groups, retrieve the best match according to our retrieval method, classify this retrieved letter as either relevant or non-relevant, update our retrieval method and present the next candidate. This is done until all relevant letters are retrieved. We try this procedure with every starting letter possible and average over those trials. Thereby we obtain a mean estimate for $FP/TP$ when trying to find the first relevant, and 50\%, 90\%, and 100\% of relevant documents for the case of each of the five diseases tested. The results of this experiment can be seen in figure \ref{fig:intelligent_search}. We start using the logistic regression classifier, after the retrieval of five false positives (a rather arbitrary value that was found through manual adjustments).

\begin{figure}[t]
	\includegraphics[width=\textwidth]{figures/intelligent_search}
	\caption{Historgram of the means (and standard errors of the means) of the false positives divided by the true positives versus how many relevant letters are retrieved for each of the five diseases---``Chronic lymphocytic leukemia'' (cll), ``multiple myeloma'' (mm), ``breast cancer'' (bc), ``follicular lymphoma'' (fl) and ``diffuse large B-cell lymphoma'' (dlbcl).}
	\label{fig:intelligent_search}
\end{figure} 

On the y-axis of this figure we plot the means and standard errors of the means of $FP/TP$ for each disease for a prespecified fraction of retrieved relevant documents. This way one can read from the plot how many false positives one has to look at to obtain a new true positive sample. In the example of cll we have to look at roughly one false positive for every five true positives we retrieve, in the case of 100\% retrieval. This makes it very convenient to search the database for more cll patients. However, as one can see from the figure it works considerably less well for other diseases. Still even in the case of dlbcl we only have to look at 3.5 false positives to get one true positive sample. For research purposes we deem this value good enough. It is also apparent from the figure that often it is relatively hard to retrieve the first match and becomes easier afterwards. One can overcome this initial phase by providing the system with several positive examples to begin with.

With this evaluation we showed that it is in principle possible to construct a research retrieval system that is usable in practice. It remains unknown though, how well this system works for less evident features than diseases. One might be interested in relatively less defining features of the document's text, than disease. In those cases it is probably harder for the system to retrieve relevant documents. A great advantage of this system, however, is that it learns from examples. One might be interested in an unusual combination of features, say for example all male smoking adults with two specific types of cancer, who suffered from depression in their youth. Retrieving letters of this patient group is hardly doable with classic string matching searches, but conceivable with the here presented method.

%We specifically address the question with how many false positives we have to deal, when trying to retrieve different fractions of the relevant letters to one of the information needs given by the diseases. We always start with one disease letter, present the best match according to our retrieval method, classify the first retrieved letter as relevant or non-relevant, update our retrieval method and present the next candidate. 



\end{document}